{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de1c5aaa",
   "metadata": {},
   "source": [
    "# Application of Transferable Adversarial Attacks on Convolutional Neuronal Networks: An Evaluation of Existing Attack and Defense Mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eae7a3",
   "metadata": {},
   "source": [
    "This code is beloinging to the bachelor thesis \"Application of Transferable Adversarial Attacks on Convolutional Neural Networks: An Evaluation of Existing Attack and Defense Mechanisms\". All results of this work can be validated and reproduced. The whole Process is divided into five phases:\n",
    "\n",
    "* **Phase 0: Initialize Project**\n",
    "\n",
    "* **Phase 1: Create Models for Evaluation**\n",
    "\n",
    "* **Phase 2: Generate (Adversarial) Datasets**\n",
    "\n",
    "* **Phase 3: Evaluate (Adversarial) Datasets on Models**\n",
    "\n",
    "* **Phase 4: Generate Visualizations of Results**\n",
    "\n",
    "To retrain models, the corresponding model must be deleted from the \"trained_models/...\" folder and phase 1 executed. The same applies to the evaluation datasets and phase 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e642723",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe902e68",
   "metadata": {},
   "source": [
    "Import all required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df390da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow, NumPy and Keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "# Enable memory growth in Tensorflow to prevent memory errors\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "for gpu_instance in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu_instance, True)\n",
    "\n",
    "# Check if files already exist\n",
    "from os.path import exists\n",
    "from data import DataLoader\n",
    "\n",
    "# Hide all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dce3ff",
   "metadata": {},
   "source": [
    "## Phase 0: Initialize Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beab2898",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Phase 0: Initialize Evaluation ---\")\n",
    "\n",
    "# only execute if the tiny ImageNet folder does not exist\n",
    "if exists(\"tiny-imagenet-200\")==False:\n",
    "    print(\"Install requirements and retrieve dataset.\")\n",
    "    \n",
    "    from init import InitProject\n",
    "    \n",
    "    # Install required packages and download tiny-imagenet-200 from Stanford repository\n",
    "    initializer = InitProject()\n",
    "    initializer.installRequirements()\n",
    "    initializer.retrieveDataset()\n",
    "    \n",
    "    # Transform downloaded dataset to Tensorflow objects and save to:\n",
    "    # \"datasets/tiny_imagenet/{training|test|validation}\"\n",
    "    loader = DataLoader()\n",
    "    loader.saveData()\n",
    "else:\n",
    "    print(\"Evaluation already initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2fae6f",
   "metadata": {},
   "source": [
    "## Phase 1: Create Models for Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2cf3a6",
   "metadata": {},
   "source": [
    "Build and train all models that we need for our evaluation (time consuming without GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4ce27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Phase 1: Create and train models ---\")\n",
    "\n",
    "# Load training and validation datasets\n",
    "training_dataset = tf.data.experimental.load(\"datasets/tiny_imagenet/training/\")\n",
    "validation_dataset = tf.data.experimental.load(\"datasets/tiny_imagenet/validation/\")\n",
    "\n",
    "# 1. Base model\n",
    "\n",
    "from training import BaseModelGenerator\n",
    "baseGen = BaseModelGenerator()\n",
    "\n",
    "# Generate a target base model\n",
    "if exists(\"trained_models/target.h5\")==False:\n",
    "    print(\"Create target model.\")\n",
    "    baseGen.generateBaseModel(training_dataset,\n",
    "                              validation_dataset,\n",
    "                              name=\"target\")\n",
    "else:\n",
    "    print(\"Target model exists.\")\n",
    "\n",
    "\n",
    "# Generate a substitute base model\n",
    "if exists(\"trained_models/substitute.h5\")==False:\n",
    "    print(\"Create substitute model.\")\n",
    "    baseGen.generateBaseModel(training_dataset,\n",
    "                              validation_dataset,\n",
    "                              name=\"substitute\")\n",
    "else:\n",
    "    print(\"Substitute model exists.\")\n",
    "    \n",
    "# 2. Adversarial Training model\n",
    "\n",
    "from training_AdversarialTraining import AdversarialTrainingGenerator\n",
    "adversarialTrainingGen = AdversarialTrainingGenerator()\n",
    "\n",
    "# Generate a adversarial training model\n",
    "if exists(\"trained_models/defenses/adversarial_training/adversarial_training.h5\")==False:\n",
    "    print(\"Create Adversarial Training model.\")\n",
    "    adversarialTrainingGen.generateAdversarialTrainingModel(training_dataset, \n",
    "                                                        validation_dataset, \n",
    "                                                        alpha=0.5,\n",
    "                                                        eps=16.0,\n",
    "                                                        name=\"adversarial_training\")\n",
    "else:\n",
    "    print(\"Adversarial Training model exists.\")\n",
    "    \n",
    "if exists(\"trained_models/defenses/adversarial_training/adversarial_training_with_sampling.h5\")==False:\n",
    "    print(\"Create Adversarial Training model with sampling from U(0,32).\")\n",
    "    adversarialTrainingGen.generateAdversarialTrainingModel(training_dataset, \n",
    "                                                        validation_dataset, \n",
    "                                                        alpha=0.5,\n",
    "                                                        eps_sample=True,\n",
    "                                                        name=\"adversarial_training_with_sampling\")\n",
    "else:\n",
    "    print(\"Adversarial Training model with sampling from U(0,32) exists.\")\n",
    "    \n",
    "# 3. Madry model\n",
    "\n",
    "from training_Madry import MadryGenerator\n",
    "madryGen = MadryGenerator()\n",
    "\n",
    "# Generate a madry defense model with eps=8.0, nb_iter=10\n",
    "if exists(\"trained_models/defenses/madry/madry_e8_n10.h5\")==False:\n",
    "    print(\"Create Madry model with eps 8 and n 10.\")\n",
    "    madryGen.generateMadryModel(training_dataset, \n",
    "                                validation_dataset, \n",
    "                                alpha=0.5,\n",
    "                                eps=8.0,\n",
    "                                eps_iter=0.8,\n",
    "                                nb_iter=10,\n",
    "                                name=\"madry_e8_n10\")\n",
    "else:\n",
    "    print(\"Madry defense model with eps 8 and n 10 exists.\")\n",
    "\n",
    "# Generate a madry defense model with eps=16.0, nb_iter=20\n",
    "if exists(\"trained_models/defenses/madry/madry_e16_n20.h5\")==False:\n",
    "    print(\"Create Madry model with eps 16 and n 20.\")\n",
    "    madryGen.generateMadryModel(training_dataset, \n",
    "                                validation_dataset, \n",
    "                                alpha=0.5,\n",
    "                                eps=16.0,\n",
    "                                eps_iter=0.8,\n",
    "                                nb_iter=20,\n",
    "                                name=\"madry_e16_n20\")\n",
    "else:\n",
    "    print(\"Madry defense model with eps 16 and n 20 exists.\")\n",
    "    \n",
    "# 4. Seiler model\n",
    "\n",
    "from training_Seiler import SeilerGenerator\n",
    "superimposingGen = SeilerGenerator()\n",
    "\n",
    "# Generate a superimposing defense model with lambda=0\n",
    "if exists(\"trained_models/defenses/seiler/seiler_lambda0.h5\")==False:\n",
    "    print(\"Create Superimposing defense model with lambda 0.\")\n",
    "    superimposingGen.generateSeilerModel(training_dataset,\n",
    "                                         validation_dataset,\n",
    "                                         _lambda=0,\n",
    "                                        name=\"seiler_lambda0\")\n",
    "else:\n",
    "    print(\"Superimposing defense model with lambda 0 exists.\")\n",
    "\n",
    "\n",
    "# Generata a superimposing defense model with lambda=10\n",
    "if exists(\"trained_models/defenses/seiler/seiler_lambda10.h5\")==False:\n",
    "    print(\"Create Superimposing defense model with lambda 10.\")\n",
    "    superimposingGen.generateSeilerModel(training_dataset,\n",
    "                                         validation_dataset,\n",
    "                                         _lambda=10,\n",
    "                                         name=\"seiler_lambda10\")\n",
    "else:\n",
    "    print(\"Superimposing defense model with lambda 10 exists.\")\n",
    "\n",
    "# 5. Defensive Destilation model\n",
    "\n",
    "from training_DefensiveDistillation import DefensiveDistillationGenerator\n",
    "ddGenerator = DefensiveDistillationGenerator()\n",
    "\n",
    "# Generate a defensive destilation model with tau=50\n",
    "if exists(\"trained_models/defenses/defensive_distillation/defensive_distillation.h5\")==False:\n",
    "    print(\"Create defensive destillation model with tau 50.\")\n",
    "    ddGenerator.generateDefensiveDistillationModel(training_dataset, \n",
    "                                                   validation_dataset,\n",
    "                                                   train_temp=50,\n",
    "                                                   epochs=100)\n",
    "else:\n",
    "    print(\"Defensive destillation model with tau 50 exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe745b",
   "metadata": {},
   "source": [
    "## Phase 2: Generate (Adversarial) Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ce8765",
   "metadata": {},
   "source": [
    "Based on the subsitute, create all black-box datasets we need for the evaluation (time consuming without GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Phase 2: Generate adversarial datasets ---\")\n",
    "\n",
    "# load the subsitute we use for the creation of the datasets\n",
    "model_substitute = tf.keras.models.load_model(\"trained_models/substitute.h5\")\n",
    "\n",
    "\n",
    "# Create 100% accuracy evalaution dataset based on testing dataset and substitute model\n",
    "if exists(\"datasets/evaluation_clean/dataset_spec.pb\")==False:\n",
    "    print(\"Create clean evaluation dataset.\")\n",
    "    testing_dataset = tf.data.experimental.load(\"datasets/tiny_imagenet/testing/\")\n",
    "    loader = DataLoader()\n",
    "    loader.generate_clean_evaluation_dataset(testing_dataset, model_substitute)\n",
    "else:\n",
    "    print(\"Clean evaluation dataset already exists.\")\n",
    "\n",
    "clean_dataset = tf.data.experimental.load(\"datasets/evaluation_clean/\")\n",
    "\n",
    "# 1. Generate adversarial datasts with momentum attack\n",
    "\n",
    "from attack_momentum import MomentumAttack\n",
    "MI_FGSM = MomentumAttack()\n",
    "\n",
    "if exists(\"datasets/adversarial_datasets/MI-FGSMAttack/e4/dataset_spec.pb\")==False:\n",
    "    \n",
    "    print(\"MI-FGSM with epsilon=4\")\n",
    "    MI_FGSM.generateDataset(\"MI-FGSMAttack\",\n",
    "                            clean_dataset, \n",
    "                            model_substitute, \n",
    "                            eps=4.0, \n",
    "                            eps_iter=4.0/20, \n",
    "                            nb_iter=20,\n",
    "                            norm=np.inf,\n",
    "                            spec=\"e4\")\n",
    "\n",
    "    print(\"MI-FGSM with epsilon=8\")\n",
    "    MI_FGSM.generateDataset(\"MI-FGSMAttack\",\n",
    "                            clean_dataset, \n",
    "                            model_substitute, \n",
    "                            eps=8.0, \n",
    "                            eps_iter=8.0/20, \n",
    "                            nb_iter=20,\n",
    "                            norm=np.inf,\n",
    "                            spec=\"e8\")\n",
    "\n",
    "    print(\"MI-FGSM with epsilon=16\")\n",
    "    MI_FGSM.generateDataset(\"MI-FGSMAttack\",\n",
    "                            clean_dataset, \n",
    "                            model_substitute, \n",
    "                            eps=16.0, \n",
    "                            eps_iter=16.0/20, \n",
    "                            nb_iter=20,\n",
    "                            norm=np.inf,\n",
    "                            spec=\"e16\")\n",
    "\n",
    "    print(\"MI-FGSM with epsilon=32\")\n",
    "    MI_FGSM.generateDataset(\"MI-FGSMAttack\",\n",
    "                            clean_dataset, \n",
    "                            model_substitute, \n",
    "                            eps=32.0, \n",
    "                            eps_iter=32.0/20, \n",
    "                            nb_iter=20,\n",
    "                            norm=np.inf,\n",
    "                            spec=\"e32\")\n",
    "else:\n",
    "    print(\"MI-FGSM adversarial Dataset exists\")\n",
    "    \n",
    "from attack_noise import NoiseAttack\n",
    "Noise = NoiseAttack()\n",
    "    \n",
    "if exists(\"datasets/evaluation_noise/dataset_spec.pb\")==False:\n",
    "    print(\"Random noise dataset with epsilon=8\")\n",
    "    Noise.generateDataset(clean_dataset, \n",
    "                          model_substitute, \n",
    "                          eps=8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac394f0",
   "metadata": {},
   "source": [
    "## Phase 3: Evaluate (Adversarial) Datasets on Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca4872",
   "metadata": {},
   "source": [
    "Phase 4 **-> Evaluation.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4f5f54",
   "metadata": {},
   "source": [
    "## Phase 4: Generate Visualizations of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e78daf",
   "metadata": {},
   "source": [
    "Phase 5 **-> Results.ipynb**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
